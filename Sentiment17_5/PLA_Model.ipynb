{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PnSRFE8Pkpd_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nHAye1AkpeD"
   },
   "outputs": [],
   "source": [
    "def h(w, X):\n",
    "    return np.sign(np.dot(w.T, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9MhvDwMkpeH"
   },
   "outputs": [],
   "source": [
    "#Kiểm tra thuật toán có hội tụ không\n",
    "def has_converged(X, y, w):\n",
    "    return np.array_equal(h(w, X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KM3QAFCakpeK"
   },
   "outputs": [],
   "source": [
    "def perceptron(X, y, w_init,loopmax, l_rate = 1, nEpoches=100000):\n",
    "    w = [w_init]\n",
    "    d, N = X.shape\n",
    "    loop=0\n",
    "    \n",
    "    while True:\n",
    "#     for ep in range(nEpoches):\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in range(N):\n",
    "            xi = X[:, mix_id[i]].reshape(d, 1)\n",
    "            yi = y[mix_id[i]]\n",
    "            \n",
    "            if h(w[-1], xi)[0] != yi:\n",
    "                w_new = w[-1] + l_rate*yi*xi\n",
    "                w.append(w_new)\n",
    "        if has_converged(X, y, w[-1]):\n",
    "            break\n",
    "        if(loop>=loopmax):\n",
    "            break\n",
    "        loop+=1\n",
    "    #print(loop)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTOEsUgykpeT"
   },
   "outputs": [],
   "source": [
    "#classify with X is a matrix (N,D),  is the number of samples, D is the number of feature\n",
    "def predict(w, X):\n",
    "    y = []\n",
    "    res = np.zeros(X.shape[1])\n",
    "    res[np.where(h(w,X)> 0)[0]]=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhws_75gkpeV"
   },
   "outputs": [],
   "source": [
    "#accurracy of Model with w parameter\n",
    "def accurracy(w,X, y):\n",
    "    y_predict = predict(w,X)\n",
    "    N=X.shape[1]\n",
    "    count=0\n",
    "    for m in range(N):\n",
    "        if (y_predict[m] == y[m]):\n",
    "            count+=1;\n",
    "    return count/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KPgok-ApkpeZ",
    "outputId": "594b247b-73df-4e5d-9ba1-17406f0e2d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dict folder 1: 1613\n",
      "accurracy_test of folder 1:  0.3598014888337469\n",
      "accurracy_train of folder 1:  0.36577805331680097\n",
      "len of dict folder 2: 1613\n",
      "accurracy_test of folder 2:  0.3573200992555831\n",
      "accurracy_train of folder 2:  0.36639801611903283\n",
      "len of dict folder 3: 1613\n",
      "accurracy_test of folder 3:  0.40694789081885857\n",
      "accurracy_train of folder 3:  0.3539987600743955\n",
      "len of dict folder 4: 1613\n",
      "accurracy_test of folder 4:  0.2555831265508685\n",
      "accurracy_train of folder 4:  0.39243645381277126\n",
      "len of dict folder 5: 1613\n",
      "accurracy_test of folder 5:  0.4392059553349876\n",
      "accurracy_train of folder 5:  0.3465592064476131\n",
      "average accurracy_train :  0.3650340979541227\n",
      "average accurracy_test :  0.363771712158809\n"
     ]
    }
   ],
   "source": [
    "sum_acc_test = 0\n",
    "aver_acc_test = 0\n",
    "sum_acc_train = 0\n",
    "aver_acc_train = 0\n",
    "for i in range(1, 6):\n",
    "    A = np.loadtxt('TxtBinaryData/train{}.txt'.format(i))\n",
    "    X_train = np.array(A[:, 1: ]).T\n",
    "    print('len of dict folder {}:'.format(i), X_train.shape[1])\n",
    "    y_train = np.array(A[:, 0])\n",
    "#     print(y_train)\n",
    "    T = np.loadtxt('TxtBinaryData/test{}.txt'.format(i))\n",
    "    X_test=np.array(T[:, 1: ]).T\n",
    "    y_test=np.array(T[:, 0])\n",
    "    \n",
    "    w_init = np.random.randn(X_train.shape[0], 1)\n",
    "    \n",
    "    y_train_t = []\n",
    "    for y_t in y_train:\n",
    "        if y_t == 0:\n",
    "            y_train_t.append(-1)\n",
    "        else:\n",
    "            y_train_t.append(1)\n",
    "    \n",
    "    w = perceptron(X_train, y_train_t, w_init,100)\n",
    "    \n",
    "    acc_test=accurracy(w[-1],X_test, y_test)\n",
    "    acc_train = accurracy(w[-1],X_train, y_train)\n",
    "    sum_acc_test = sum_acc_test + acc_test\n",
    "    sum_acc_train = sum_acc_train + acc_train\n",
    "    print('accurracy_test of folder {}: '.format(i), acc_test)\n",
    "    print('accurracy_train of folder {}: '.format(i), acc_train)\n",
    "aver_acc_train = sum_acc_train/5\n",
    "aver_acc_test = sum_acc_test/5\n",
    "print('average accurracy_train : ', aver_acc_train)\n",
    "print('average accurracy_test : ', aver_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PLA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
