{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dict folder 1: 1413\n",
      "accurracy_test of folder 1:  0.8287841191066998\n",
      "accurracy_train of folder 1:  0.9938003719776813\n",
      "len of dict folder 2: 1418\n",
      "accurracy_test of folder 2:  0.7816377171215881\n",
      "accurracy_train of folder 2:  0.9832610043397396\n",
      "len of dict folder 3: 1373\n",
      "accurracy_test of folder 3:  0.749379652605459\n",
      "accurracy_train of folder 3:  0.9318040917544947\n",
      "len of dict folder 4: 1430\n",
      "accurracy_test of folder 4:  0.8188585607940446\n",
      "accurracy_train of folder 4:  0.9851208927464352\n",
      "len of dict folder 5: 1401\n",
      "accurracy_test of folder 5:  0.7965260545905707\n",
      "accurracy_train of folder 5:  0.9956602603843769\n",
      "average accurracy_train :  0.9779293242405457\n",
      "average accurracy_test :  0.7950372208436725\n"
     ]
    }
   ],
   "source": [
    "sum_acc_test = 0\n",
    "aver_acc_test = 0\n",
    "sum_acc_train = 0\n",
    "aver_acc_train = 0\n",
    "for i in range(1, 6):\n",
    "    A = np.loadtxt('TxtBinaryData/train{}.txt'.format(i))\n",
    "    X_train = np.array(A[:, 1: ])\n",
    "    print('len of dict folder {}:'.format(i), X_train.shape[1])\n",
    "    y_train = np.array(A[:, 0])\n",
    "    T = np.loadtxt('TxtBinaryData/test{}.txt'.format(i))\n",
    "    X_test=np.array(T[:, 1: ])\n",
    "    y_test=np.array(T[:, 0])\n",
    "    \n",
    "    clf = Perceptron(tol=1e-3, random_state=0)\n",
    "    clf.fit(X_train, y_train)  \n",
    "    acc_train=clf.score(X_train, y_train)\n",
    "    acc_test =clf.score(X_test, y_test)\n",
    "    sum_acc_test = sum_acc_test + acc_test\n",
    "    sum_acc_train = sum_acc_train + acc_train\n",
    "    print('accurracy_test of folder {}: '.format(i), acc_test)\n",
    "    print('accurracy_train of folder {}: '.format(i), acc_train)\n",
    "aver_acc_train = sum_acc_train/5\n",
    "aver_acc_test = sum_acc_test/5\n",
    "print('average accurracy_train : ', aver_acc_train)\n",
    "print('average accurracy_test : ', aver_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
